{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from abc import ABC\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "stopWords_nltk = set(stopwords.words('english'))\n",
    "stopWords_spc = {'those', 'on', 'own', '’ve', 'yourselves', 'around', 'between', 'four', 'been', 'alone', 'off', 'am',\n",
    "                 'then', 'other', 'can', 'regarding', 'hereafter', 'front', 'too', 'used', 'wherein', '‘ll', 'doing',\n",
    "                 'everything', 'up', 'onto', 'never', 'either', 'how', 'before', 'anyway', 'since', 'through', 'amount',\n",
    "                 'now', 'he', 'was', 'have', 'into', 'because', 'not', 'therefore', 'they', 'n’t', 'even', 'whom', 'it',\n",
    "                 'see', 'somewhere', 'thereupon', 'nothing', 'whereas', 'much', 'whenever', 'seem', 'until', 'whereby',\n",
    "                 'at', 'also', 'some', 'last', 'than', 'get', 'already', 'our', 'once', 'will', 'noone', \"'m\", 'that',\n",
    "                 'what', 'thus', 'no', 'myself', 'out', 'next', 'whatever', 'although', 'though', 'which', 'would',\n",
    "                 'therein', 'nor', 'somehow', 'whereupon', 'besides', 'whoever', 'ourselves', 'few', 'did', 'without',\n",
    "                 'third', 'anything', 'twelve', 'against', 'while', 'twenty', 'if', 'however', 'herself', 'when', 'may',\n",
    "                 'ours', 'six', 'done', 'seems', 'else', 'call', 'perhaps', 'had', 'nevertheless', 'where', 'otherwise',\n",
    "                 'still', 'within', 'its', 'for', 'together', 'elsewhere', 'throughout', 'of', 'others', 'show', '’s',\n",
    "                 'anywhere', 'anyhow', 'as', 'are', 'the', 'hence', 'something', 'hereby', 'nowhere', 'latterly', 'say',\n",
    "                 'does', 'neither', 'his', 'go', 'forty', 'put', 'their', 'by', 'namely', 'could', 'five', 'unless',\n",
    "                 'itself', 'is', 'nine', 'whereafter', 'down', 'bottom', 'thereby', 'such', 'both', 'she', 'become',\n",
    "                 'whole', 'who', 'yourself', 'every', 'thru', 'except', 'very', 'several', 'among', 'being', 'be',\n",
    "                 'mine', 'further', 'n‘t', 'here', 'during', 'why', 'with', 'just', \"'s\", 'becomes', '’ll', 'about',\n",
    "                 'a', 'using', 'seeming', \"'d\", \"'ll\", \"'re\", 'due', 'wherever', 'beforehand', 'fifty', 'becoming',\n",
    "                 'might', 'amongst', 'my', 'empty', 'thence', 'thereafter', 'almost', 'least', 'someone', 'often',\n",
    "                 'from', 'keep', 'him', 'or', '‘m', 'top', 'her', 'nobody', 'sometime', 'across', '‘s', '’re',\n",
    "                 'hundred', 'only', 'via', 'name', 'eight', 'three', 'back', 'to', 'all', 'became', 'move', 'me', 'we',\n",
    "                 'formerly', 'so', 'i', 'whence', 'under', 'always', 'himself', 'in', 'herein', 'more', 'after',\n",
    "                 'themselves', 'you', 'above', 'sixty', 'them', 'your', 'made', 'indeed', 'most', 'everywhere',\n",
    "                 'fifteen', 'but', 'must', 'along', 'beside', 'hers', 'side', 'former', 'anyone', 'full', 'has',\n",
    "                 'yours', 'whose', 'behind', 'please', 'ten', 'seemed', 'sometimes', 'should', 'over', 'take', 'each',\n",
    "                 'same', 'rather', 'really', 'latter', 'and', 'ca', 'hereupon', 'part', 'per', 'eleven', 'ever', '‘re',\n",
    "                 'enough', \"n't\", 'again', '‘d', 'us', 'yet', 'moreover', 'mostly', 'one', 'meanwhile', 'whither',\n",
    "                 'there', 'toward', '’m', \"'ve\", '’d', 'give', 'do', 'an', 'quite', 'these', 'everyone', 'towards',\n",
    "                 'this', 'cannot', 'afterwards', 'beyond', 'make', 'were', 'whether', 'well', 'another', 'below',\n",
    "                 'first', 'upon', 'any', 'none', 'many', 'serious', 'various', 're', 'two', 'less', '‘ve'}\n",
    "stopWords_s = stopWords_spc | stopWords_nltk | STOPWORDS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_general = gensim.models.Word2Vec.load(os.path.join('./models', 'general.model'))\n",
    "\n",
    "FASTEXTW2V = os.path.join('./models', 'wiki-news-300d-1M-subword.vec')\n",
    "groundw2v = KeyedVectors.load_word2vec_format(FASTEXTW2V)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aclu', 'Aew', 'Aoc', 'Arbery', 'Backgrid', 'Bankman', 'Bhr', 'Blm', 'Bobulinski', 'Bodycam', 'Boebert', 'Bolsonaro', 'Breonna', 'Cefc', 'Cnbc', 'Cnnmoney', 'Cnnopinion', 'Cnp', 'Covid', 'Crimo', 'Crumbley', 'Dcpi', 'Depape', 'Desantis', 'Doj', 'Fdny', 'Filmmagic', 'Ftx', 'Gofundme', 'Heastie', 'Hhs', 'Iaea', 'Ioc', 'Istockphoto', 'Jpmorgan', 'Keivom', 'Kohberger', 'Kuleba', 'Kyrsten', 'Lapd', 'Laundrie', 'Lgbtq', 'Lightrocket', 'Malliotakis', 'Martinka', 'Mcauliffe', 'Mccabe', 'Mccaul', 'Mcconnell', 'Mcdermott', 'Mcmaster', 'Mcmichael', 'Metoo', 'Murdaugh', 'Naacp', 'Nbcu', 'Nurphoto', 'Nypost', 'Prigozhin', 'Qanon', 'Realdonaldtrump', 'Rnc', 'Saipov', 'Snl', 'Somodevilla', 'Sondland', 'Spacex', 'Splashnews', 'Swns', 'Tiktok', 'Tlaib', 'Tmz', 'Vindman', 'Vucci', 'Wenzelberg', 'Wireimage', 'Wnba', 'Youngkin', 'Yovanovitch', 'Zelensky', 'Zumapress']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(sorted(list(model_general.wv.index_to_key)))\n",
    "vocab = [w for w in vocab if w not in stopWords_s]\n",
    "for idx, w in enumerate(vocab):\n",
    "    if w not in groundw2v.key_to_index.keys():\n",
    "        vocab[idx] = w.title()\n",
    "mtx = np.vstack([groundw2v[w] for w in vocab if w in groundw2v.key_to_index.keys()])\n",
    "drop_words = [w for w in vocab if w not in groundw2v.key_to_index.keys()]\n",
    "print(drop_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [108]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m clustering \u001B[38;5;241m=\u001B[39m \u001B[43mKMeans\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmtx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m res \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c, w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(clustering\u001B[38;5;241m.\u001B[39mlabels_, vocab):\n",
      "File \u001B[0;32m~/Opt/anaconda3/envs/m1_torch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1410\u001B[0m, in \u001B[0;36mKMeans.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1406\u001B[0m best_inertia, best_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1408\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_init):\n\u001B[1;32m   1409\u001B[0m     \u001B[38;5;66;03m# Initialize centers\u001B[39;00m\n\u001B[0;32m-> 1410\u001B[0m     centers_init \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_centroids\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_squared_norms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[1;32m   1412\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1413\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[1;32m   1414\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitialization complete\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Opt/anaconda3/envs/m1_torch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:952\u001B[0m, in \u001B[0;36m_BaseKMeans._init_centroids\u001B[0;34m(self, X, x_squared_norms, init, random_state, init_size, n_centroids)\u001B[0m\n\u001B[1;32m    949\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    951\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(init, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m init \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk-means++\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 952\u001B[0m     centers, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_kmeans_plusplus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    953\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    954\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    955\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    956\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx_squared_norms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    957\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    958\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(init, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m init \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    959\u001B[0m     seeds \u001B[38;5;241m=\u001B[39m random_state\u001B[38;5;241m.\u001B[39mpermutation(n_samples)[:n_clusters]\n",
      "File \u001B[0;32m~/Opt/anaconda3/envs/m1_torch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:224\u001B[0m, in \u001B[0;36m_kmeans_plusplus\u001B[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001B[0m\n\u001B[1;32m    221\u001B[0m np\u001B[38;5;241m.\u001B[39mclip(candidate_ids, \u001B[38;5;28;01mNone\u001B[39;00m, closest_dist_sq\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, out\u001B[38;5;241m=\u001B[39mcandidate_ids)\n\u001B[1;32m    223\u001B[0m \u001B[38;5;66;03m# Compute distances to center candidates\u001B[39;00m\n\u001B[0;32m--> 224\u001B[0m distance_to_candidates \u001B[38;5;241m=\u001B[39m \u001B[43m_euclidean_distances\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcandidate_ids\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_norm_squared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;66;03m# update closest distances squared and potential for each candidate\u001B[39;00m\n\u001B[1;32m    229\u001B[0m np\u001B[38;5;241m.\u001B[39mminimum(closest_dist_sq, distance_to_candidates, out\u001B[38;5;241m=\u001B[39mdistance_to_candidates)\n",
      "File \u001B[0;32m~/Opt/anaconda3/envs/m1_torch/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:366\u001B[0m, in \u001B[0;36m_euclidean_distances\u001B[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001B[0m\n\u001B[1;32m    361\u001B[0m         YY \u001B[38;5;241m=\u001B[39m row_norms(Y, squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[np\u001B[38;5;241m.\u001B[39mnewaxis, :]\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat32:\n\u001B[1;32m    364\u001B[0m     \u001B[38;5;66;03m# To minimize precision issues with float32, we compute the distance\u001B[39;00m\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;66;03m# matrix on chunks of X and Y upcast to float64\u001B[39;00m\n\u001B[0;32m--> 366\u001B[0m     distances \u001B[38;5;241m=\u001B[39m \u001B[43m_euclidean_distances_upcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mYY\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    368\u001B[0m     \u001B[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001B[39;00m\n\u001B[1;32m    369\u001B[0m     distances \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m safe_sparse_dot(X, Y\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Opt/anaconda3/envs/m1_torch/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:564\u001B[0m, in \u001B[0;36m_euclidean_distances_upcast\u001B[0;34m(X, XX, Y, YY, batch_size)\u001B[0m\n\u001B[1;32m    562\u001B[0m Y_chunk \u001B[38;5;241m=\u001B[39m Y[y_slice]\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m YY \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 564\u001B[0m     YY_chunk \u001B[38;5;241m=\u001B[39m \u001B[43mrow_norms\u001B[49m\u001B[43m(\u001B[49m\u001B[43mY_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m[np\u001B[38;5;241m.\u001B[39mnewaxis, :]\n\u001B[1;32m    565\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    566\u001B[0m     YY_chunk \u001B[38;5;241m=\u001B[39m YY[:, y_slice]\n",
      "File \u001B[0;32m~/Opt/anaconda3/envs/m1_torch/lib/python3.8/site-packages/sklearn/utils/extmath.py:75\u001B[0m, in \u001B[0;36mrow_norms\u001B[0;34m(X, squared)\u001B[0m\n\u001B[1;32m     73\u001B[0m     norms \u001B[38;5;241m=\u001B[39m csr_row_norms(X)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 75\u001B[0m     norms \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mij,ij->i\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m squared:\n\u001B[1;32m     78\u001B[0m     np\u001B[38;5;241m.\u001B[39msqrt(norms, norms)\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36meinsum\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/Opt/anaconda3/envs/m1_torch/lib/python3.8/site-packages/numpy/core/einsumfunc.py:1371\u001B[0m, in \u001B[0;36meinsum\u001B[0;34m(out, optimize, *operands, **kwargs)\u001B[0m\n\u001B[1;32m   1369\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m specified_out:\n\u001B[1;32m   1370\u001B[0m         kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m out\n\u001B[0;32m-> 1371\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mc_einsum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moperands\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001B[39;00m\n\u001B[1;32m   1374\u001B[0m \u001B[38;5;66;03m# repeat default values here\u001B[39;00m\n\u001B[1;32m   1375\u001B[0m valid_einsum_kwargs \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124morder\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcasting\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "clustering = KMeans(n_clusters=300).fit(mtx)\n",
    "res = {}\n",
    "for c, w in zip(clustering.labels_, vocab):\n",
    "    c = str(c)\n",
    "    if c not in res:\n",
    "        res[c] = []\n",
    "    res[c].append(w)\n",
    "json.dump(res, open(os.path.join('./models', 'ground_clustering.tpc'), 'w'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "t_num = []\n",
    "t_words = []\n",
    "t_name = []\n",
    "for k in res.keys():\n",
    "    t_num.append(k)\n",
    "    t_words.append(res[k])\n",
    "    t_name.append([])\n",
    "pd.DataFrame({'id': t_num, 'name': t_name, 'words': t_words}).to_csv('./ground_topics.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vocab = list(sorted(list(model_general.wv.index_to_key)))\n",
    "vocab = [w for w in vocab if w not in stopWords_s]\n",
    "mtx = np.vstack([model_general.wv[w] for w in vocab])\n",
    "\n",
    "clustering = KMeans(n_clusters=300).fit(mtx)\n",
    "res = {}\n",
    "t_align = {}\n",
    "for c, w in zip(clustering.labels_, vocab):\n",
    "    t_align[w] = c\n",
    "    c = str(c)\n",
    "    if c not in res:\n",
    "        res[c] = []\n",
    "    res[c].append(w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "#json.dump(t_align, open(os.path.join('./models', 'news_clustering.ali'), 'w'))\n",
    "json.dump(res, open(os.path.join('./models', 'news_clustering.tpc'), 'w'))\n",
    "\n",
    "t_num = []\n",
    "t_words = []\n",
    "t_name = []\n",
    "for k in res.keys():\n",
    "    t_num.append(k)\n",
    "    t_words.append(res[k])\n",
    "    t_name.append([])\n",
    "pd.DataFrame({'id': t_num, 'name': t_name, 'words': t_words}).to_csv('./news_topics.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_general=gensim.models.Word2Vec.load(os.path.join('./models', 'general.model'))\n",
    "model_nypost = gensim.models.Word2Vec.load(os.path.join('./models', 'nypost.model'))\n",
    "model_cnn = gensim.models.Word2Vec.load(os.path.join('./models', 'cnn.model'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[(3, 'and', 'of'),\n (4, 'of', 'and'),\n (7, 'for', 'on'),\n (8, 'on', 'for'),\n (10, 'was', 'said'),\n (11, 'with', 'it'),\n (13, 'it', 'was'),\n (14, 'said', 'with'),\n (16, 'his', 'at'),\n (17, 'at', 'his'),\n (18, 'by', 'have'),\n (19, 'from', 'are'),\n (20, 'have', 'has'),\n (21, 'be', 'from'),\n (22, 'has', 'by'),\n (23, 'are', 'be'),\n (24, 'who', 'not'),\n (25, 'an', 'this'),\n (26, 'this', 'an'),\n (27, 'they', 'but'),\n (28, 'not', 'they'),\n (29, 'her', 'we'),\n (30, 'but', 'trump'),\n (31, 'we', 'who'),\n (32, 'she', 'cnn'),\n (33, 'you', 'will'),\n (34, 'their', 'were'),\n (35, 'after', 'their'),\n (36, 'new', 'been'),\n (37, 'were', 'people'),\n (39, 'had', 'us'),\n (40, 'will', 'more'),\n (41, 'one', 'president'),\n (42, 'been', 'she'),\n (44, 'up', 'had'),\n (45, 'biden', 'after'),\n (46, 'more', 'one'),\n (47, 'when', 'you'),\n (48, 'out', 'her'),\n (49, 'president', 'police'),\n (50, 'year', 'would'),\n (51, 'all', 'there'),\n (52, 'people', 'new'),\n (53, 'would', 'what'),\n (55, 'which', 'when'),\n (56, 'us', 'which'),\n (57, 'there', 'up'),\n (58, 'if', 'out'),\n (59, 'what', 'its'),\n (60, 'no', 'all'),\n (61, 'told', 'if'),\n (62, 'so', 'year'),\n (63, 'can', 'our'),\n (64, 'just', 'than'),\n (65, 'him', 'can'),\n (66, 'trump', 'no'),\n (67, 'over', 'two'),\n (68, 'two', 'told'),\n (69, 'time', 'other'),\n (70, 'our', 'over'),\n (71, 'its', 'some'),\n (72, 'than', 'state'),\n (73, 'into', 'time'),\n (74, 'last', 'so'),\n (75, 'like', 'into'),\n (77, 'police', 'according'),\n (78, 'other', 'could'),\n (79, 'my', 'last'),\n (80, 'post', 'country'),\n (81, 'state', 'him'),\n (82, 'while', 'them'),\n (83, 'them', 'house'),\n (84, 'city', 'against'),\n (85, 'during', 'just'),\n (86, 'now', 'war'),\n (87, 'do', 'like'),\n (88, 'images', 'government'),\n (89, 'before', 'during'),\n (90, 'house', 'now'),\n (91, 'some', 'do'),\n (92, 'get', 'years'),\n (93, 'according', 'those'),\n (94, 'ukraine', 'how'),\n (95, 'years', 'many'),\n (96, 'getty', 'says'),\n (97, 'because', 'while'),\n (98, 're', 'russia'),\n (99, 'could', 'states'),\n (100, 'back', 'because'),\n (101, 'only', 'before'),\n (102, 'york', 'world'),\n (103, 'even', 'white'),\n (104, 'against', 'where'),\n (105, 'former', 'most'),\n (106, 'being', 'day'),\n (107, 'russian', 'united'),\n (108, 'russia', 'any'),\n (109, 'how', 'ukraine'),\n (110, 'where', 'get'),\n (111, 'your', 'may'),\n (112, 'then', 'only'),\n (113, 'day', 'even'),\n (114, 'old', 're'),\n (115, 'off', 'being'),\n (116, 'me', 'my'),\n (117, 'most', 'say'),\n (118, 'white', 'black'),\n (119, 'any', 'did'),\n (120, 'down', 'city'),\n (121, 'don', 'images'),\n (122, 'did', 'military'),\n (123, 'going', 'security'),\n (124, 'made', 'back'),\n (125, 'since', 'video'),\n (126, 'many', 'week'),\n (127, 'week', 'since'),\n (128, 'including', 'russian'),\n (129, 'family', 'national'),\n (130, 'world', 'law'),\n (131, 'those', 'former'),\n (132, 'home', 'these'),\n (133, 'via', 'made'),\n (134, 'three', 'attack'),\n (135, 'news', 'biden'),\n (136, 'country', 'american'),\n (137, 'ap', 'including'),\n (138, 'make', 'statement'),\n (139, 'know', 'getty'),\n (140, 'may', 'then'),\n (141, 'right', 'story'),\n (142, 'should', 'officials'),\n (143, 'another', 'between'),\n (144, 'still', 'group'),\n (146, 'million', 'still'),\n (147, 'these', 'going'),\n (148, 'war', 'political'),\n (149, 'say', 'democratic'),\n (150, 'through', 'don'),\n (151, 'left', 'make'),\n (152, 'way', 'department'),\n (153, 'want', 'should'),\n (154, 'public', 'violence'),\n (155, 'well', 'public'),\n (156, 'think', 'three'),\n (157, 'called', 'very'),\n (158, 'man', 'know'),\n (159, 'very', 'down'),\n (161, 'next', 'campaign'),\n (162, 'go', 'here'),\n (163, 'law', 'through'),\n (164, 'government', 'way'),\n (165, 'around', 'called'),\n (166, 'media', 'news'),\n (167, 'american', 'family'),\n (168, 'never', 'support'),\n (169, 'long', 'killed'),\n (170, 'under', 'right'),\n (171, 'life', 'election'),\n (172, 'office', 'think'),\n (173, 'reported', 'your'),\n (174, 'show', 'tuesday'),\n (175, 'much', 'both'),\n (176, 'school', 'another'),\n (177, 'month', 'republican'),\n (178, 'added', 'administration'),\n (179, 'black', 'gun'),\n (180, 'work', 'obama'),\n (181, 'times', 'under'),\n (182, 'didn', 'part'),\n (183, 'both', 'well'),\n (184, 'see', 'party'),\n (185, 'twitter', 'women'),\n (186, 'china', 'long'),\n (187, 'officials', 'china'),\n (188, 'putin', 'office'),\n (189, 'tuesday', 'much'),\n (190, 've', 'around'),\n (191, 'states', 'monday'),\n (192, 'good', 'man'),\n (193, 'department', 'wednesday'),\n (194, 'border', 'home'),\n (195, 'monday', 'such'),\n (196, 'security', 'me'),\n (197, 'administration', 'old'),\n (198, 'military', 'off'),\n (199, 'between', 'want'),\n (200, 'found', 'see'),\n (201, 'high', 'washington'),\n (202, 'advertisement', 'work'),\n (203, 'got', 'thursday'),\n (204, 'national', 'need'),\n (205, 'later', 'friday'),\n (206, 'own', 'democrats'),\n (207, 'group', 'case'),\n (208, 'such', 'officers'),\n (209, 'part', 'rights'),\n (210, 'days', 'go'),\n (211, 'team', 'donald'),\n (212, 'says', 'ad'),\n (213, 'wednesday', 'days'),\n (214, 'same', 'members'),\n (215, 'need', 'own'),\n (216, 'four', 'york'),\n (217, 'crime', 'children'),\n (218, 'thursday', 'media'),\n (219, 'here', 'federal'),\n (220, 'children', 'clinton'),\n (221, 'took', 'report'),\n (222, 'help', 'same'),\n (223, 'federal', 'school'),\n (224, 'press', 'million'),\n (225, 'asked', 'forces'),\n (226, 'statement', 'north'),\n (227, 'every', 'source'),\n (228, 'friday', 'south'),\n (229, 'support', 'international'),\n (230, 'percent', 'senate'),\n (231, 'big', 'help'),\n (232, 'report', 'found'),\n (233, 'democrats', 'month'),\n (234, 'wrote', 'life'),\n (235, 'saying', 'america'),\n (236, 'night', 'syria'),\n (237, 'election', 'next'),\n (238, 'united', 'al'),\n (239, 'ukrainian', 'official'),\n (240, 'party', 'high'),\n (241, 'case', 'end'),\n (242, 'too', 'come'),\n (243, 'second', 'later'),\n (244, 'come', 'whether'),\n (245, 'video', 'death'),\n (246, 'best', 'never'),\n (247, 'why', 'saying'),\n (248, 'women', 'left'),\n (249, 'political', 'isis'),\n (250, 'game', 'justice'),\n (251, 'members', 'asked'),\n (252, 'without', 'used'),\n (253, 'social', 'shooting'),\n (254, 'covid', 'highlights'),\n (255, 'joe', 'use'),\n (256, 'came', 'today'),\n (257, 'really', 'americans'),\n (258, 'use', 'among'),\n (259, 'america', 'health'),\n (260, 'washington', 'place'),\n (261, 'attack', 'foreign'),\n (262, 'end', 'several'),\n (263, 'top', 'republicans'),\n (264, 'death', 'recent'),\n (265, 'months', 'attacks'),\n (266, 'went', 'border'),\n (267, 'seen', 'policy'),\n (268, 'democratic', 'community'),\n (269, 'five', 'least'),\n (270, 'used', 'why'),\n (271, 'killed', 'across'),\n (272, 'shot', 'investigation'),\n (273, 'republican', 'took'),\n (274, 'woman', 'sunday'),\n (275, 'put', 'officer'),\n (276, 'set', 'four'),\n (277, 'mayor', 've'),\n (278, 'campaign', 'putin'),\n (279, 'company', 'too'),\n (280, 'son', 'added'),\n (281, 'again', 'didn'),\n (282, 'health', 'vote'),\n (283, 'least', 'months'),\n (284, 'reuters', 'number'),\n (285, 'photo', 'every'),\n (286, 'six', 'show'),\n (287, 'far', 'countries'),\n (288, 'sunday', 'far'),\n (289, 'away', 'defense'),\n (290, 'th', 'authorities'),\n (291, 'place', 'without'),\n (292, 'bill', 'reported'),\n (293, 'call', 'times'),\n (294, 'season', 'committee'),\n (295, 'gun', 'power'),\n (296, 'violence', 'attorney'),\n (297, 'look', 'general'),\n (298, 'yet', 'leaders'),\n (299, 'face', 'night'),\n (300, 'americans', 'immigration'),\n (301, 'attorney', 'bill'),\n (302, 'won', 'came'),\n (303, 'instagram', 'things'),\n (304, 'star', 'call'),\n (305, 'street', 'men'),\n (306, 'already', 'minister'),\n (307, 'shooting', 'seen'),\n (308, 'business', 'congress'),\n (309, 'person', 'twitter'),\n (310, 'justice', 'second'),\n (311, 'hunter', 'presidential'),\n (312, 'whether', 'afp'),\n (313, 'policy', 'leader'),\n (314, 'point', 'history'),\n (315, 'something', 'past'),\n (316, 'lot', 'good'),\n (317, 'cops', 'decision'),\n (318, 'defense', 'secretary'),\n (319, 'several', 'earlier'),\n (320, 'following', 'change'),\n (321, 'things', 'top'),\n (322, 'great', 'others'),\n (323, 'recent', 'force'),\n (324, 'earlier', 'already'),\n (325, 'allegedly', 'march'),\n (326, 'head', 'put'),\n (327, 'outside', 'january'),\n (328, 'today', 'university'),\n (329, 'money', 'clear'),\n (330, 'love', 'shot'),\n (331, 'power', 'iran'),\n (332, 'among', 'crime'),\n (333, 'run', 'chief'),\n (334, 'making', 'center'),\n (335, 'past', 'deal'),\n (336, 'until', 'protesters'),\n (337, 'keep', 'saturday'),\n (338, 'better', 'nation'),\n (339, 'senate', 'away'),\n (340, 'free', 'does'),\n (341, 'west', 'team'),\n (342, 'story', 'wrote'),\n (343, 'rep', 'voters'),\n (344, 'deal', 'won'),\n (346, 'll', 'social'),\n (347, 'adams', 'likely'),\n (348, 'released', 'local'),\n (349, 'doesn', 'again'),\n (350, 'donald', 'set'),\n (351, 'across', 'point'),\n (352, 'march', 'five'),\n (353, 'republicans', 'groups'),\n (354, 'early', 'feedback'),\n (355, 'facebook', 'really'),\n (356, 'forces', 'something'),\n (357, 'trying', 'issue'),\n (358, 'getting', 'person'),\n (359, 'hit', 'information'),\n (360, 'officers', 'control'),\n (361, 'does', 'working'),\n (362, 'real', 'yet'),\n (363, 'working', 'early'),\n (364, 'once', 'issues'),\n (365, 'center', 'until'),\n (366, 'little', 'face'),\n (367, 'men', 'anti'),\n (368, 'doing', 'must'),\n (369, 'believe', 'released'),\n (370, 'claimed', 'believe'),\n (371, 'let', 'ukrainian'),\n (372, 'despite', 'few'),\n (373, 'county', 'outside'),\n (374, 'committee', 'might'),\n (375, 'each', 'taken'),\n (376, 'near', 'human'),\n (377, 'stop', 'conflict'),\n (378, 'john', 'major'),\n (379, 'always', 'near'),\n (380, 'ever', 'company'),\n (381, 'general', 'fire'),\n (382, 'number', 'led'),\n (383, 'pandemic', 'sen'),\n (384, 'wife', 'woman'),\n (385, 'must', 'weapons'),\n (386, 'local', 'doesn'),\n (387, 'young', 'held'),\n (388, 'taken', 'making'),\n (389, 'full', 'following'),\n (390, 'weeks', 'enforcement'),\n (391, 'saturday', 'november'),\n (392, 'afp', 'trying'),\n (393, 'nearly', 'look'),\n (394, 'anti', 'meeting'),\n (395, 'decision', 'race'),\n (396, 'few', 'related'),\n (397, 'late', 'lot'),\n (398, 'father', 'action'),\n (399, 'mother', 'business'),\n (400, 'others', 'lives'),\n (401, 'based', 'announced'),\n (402, 'previous', 'move'),\n (403, 'open', 'stop'),\n (404, 'james', 'known'),\n (405, 'chinese', 'weeks'),\n (406, 'behind', 'based'),\n (407, 'having', 'continue'),\n (408, 'name', 'read'),\n (409, 'however', 'system'),\n (410, 'give', 'john'),\n (411, 'chief', 'got'),\n (412, 'authorities', 'order'),\n (413, 'accused', 'each'),\n (414, 'invasion', 'director'),\n (415, 'secretary', 'act'),\n (416, 'live', 'civil'),\n (417, 'job', 'become'),\n (418, 'control', 'iraq'),\n (419, 'leader', 'run'),\n (420, 'might', 'gop'),\n (421, 'foreign', 'response'),\n (422, 'play', 'ap'),\n (423, 'judge', 'protests'),\n (424, 'less', 'free'),\n (425, 'comes', 'syrian'),\n (426, 'rights', 'young'),\n (427, 'along', 'fight'),\n (428, 'fbi', 'however'),\n (429, 'likely', 'june'),\n (430, 'district', 'facebook'),\n (431, 'taking', 'little'),\n (432, 'investigation', 'went'),\n (433, 'community', 'county'),\n (434, 'information', 'died'),\n (435, 'hochul', 'big'),\n (436, 'announced', 'district'),\n (437, 'fox', 'area'),\n (438, 'clear', 'agency'),\n (439, 'change', 'different'),\n (440, 'win', 'best'),\n (441, 'order', 'post'),\n (442, 'known', 'care'),\n (443, 'service', 'air'),\n (444, 'criminal', 'important'),\n (445, 'kids', 'comes'),\n (446, 'nypd', 'korea'),\n (447, 'history', 'great'),\n (448, 'held', 'evidence'),\n (449, 'system', 'ago'),\n (450, 'official', 'region'),\n (451, 'thing', 'able'),\n (452, 'congress', 'legal'),\n (453, 'texas', 'intelligence'),\n (454, 'gov', 'september'),\n (455, 'charges', 'troops'),\n (456, 'enough', 'began'),\n (457, 'ago', 'economic'),\n (458, 'hours', 'morning'),\n (459, 'reportedly', 'service'),\n (460, 'feel', 'victims'),\n (461, 'fire', 'press'),\n (462, 'able', 'plan'),\n (463, 'led', 'west'),\n (464, 'nation', 'start'),\n (465, 'died', 'process'),\n (466, 'himself', 'taking'),\n (467, 'force', 'once'),\n (468, 'hard', 'less'),\n (469, 'lives', 'behind'),\n (470, 'shows', 'sign'),\n (471, 'side', 'better'),\n (472, 'address', 'july'),\n (473, 'nothing', 'open'),\n (474, 'continued', 'doing'),\n (475, 'officer', 'chinese'),\n (476, 'start', 'crisis'),\n (477, 'south', 'europe'),\n (478, 'billion', 'nearly'),\n (479, 'june', 'keep'),\n (480, 'line', 'european'),\n (481, 'international', 'protest'),\n (482, 'become', 'sanders'),\n (483, 'plan', 'fact'),\n (484, 'parents', 'efforts'),\n (485, 'vote', 'speech'),\n (486, 'north', 'california'),\n (487, 'claims', 'prime'),\n (488, 'continue', 'union'),\n (489, 'began', 'money'),\n (490, 'air', 'cases'),\n (491, 'done', 'matter'),\n (492, 'together', 'students'),\n (493, 'move', 'six'),\n (494, 'manhattan', 'threat'),\n (495, 'close', 'trade'),\n (496, 'wanted', 'despite'),\n (497, 'find', 'global'),\n (498, 'arrested', 'interview'),\n (499, 'building', 'debate'),\n (500, 'third', 'february'),\n (501, 'fight', 'let'),\n (502, 'fact', 'families'),\n (503, 'special', 'nuclear'),\n (504, 'daughter', 'incident'),\n (505, 'murder', 'given'),\n (506, 'share', 'texas'),\n (507, 'alleged', 'senior'),\n (508, 'recently', 'possible'),\n (509, 'wasn', 'october'),\n (510, 'car', 'arrested'),\n (511, 'email', 'head'),\n (512, 'lost', 'hours'),\n (513, 'morning', 'august'),\n (514, 'board', 'find'),\n (515, 'inside', 'future'),\n (516, 'university', 'close'),\n (517, 'brooklyn', 'give'),\n (518, 'july', 'criminal'),\n (519, 'coming', 'ever'),\n (520, 'major', 'along'),\n (521, 'east', 'charges'),\n (522, 'iran', 'often'),\n (523, 'care', 'real'),\n (524, 'child', 'israel'),\n (525, 'looking', 'situation'),\n (526, 'de', 'together'),\n (527, 'front', 'full'),\n (528, 'due', 'role'),\n (529, 'instead', 'done'),\n (530, 'meeting', 'within'),\n (531, 'nuclear', 'himself'),\n (532, 'hospital', 'special'),\n (533, 'interview', 'further'),\n (534, 'migrants', 'majority'),\n (535, 'comment', 'late'),\n (536, 'director', 'line'),\n (537, 'charged', 'peace'),\n (538, 'different', 'win'),\n (540, 'co', 'nations'),\n (541, 'latest', 'question'),\n (542, 'everything', 'joe'),\n (543, 'important', 'key'),\n (544, 'matter', 'program'),\n (545, 'started', 'name'),\n (546, 'response', 'enough'),\n (547, 'safety', 'member'),\n (548, 'someone', 'using'),\n (549, 'jan', 'live'),\n (550, 'using', 'release'),\n (551, 'obama', 'expected'),\n (552, 'governor', 'front'),\n (553, 'leaders', 'll'),\n (554, 'reports', 'th'),\n (555, 'anything', 'florida'),\n (556, 'couple', 'always'),\n (557, 'agency', 'terror'),\n (558, 'students', 'coming'),\n (559, 'issue', 'shows'),\n (560, 'act', 'african'),\n (561, 'expected', 'accused'),\n (562, 'given', 'thousands'),\n (563, 'friend', 'hard'),\n (564, 'am', 'judge'),\n (565, 'window', 'latest'),\n (566, 'speech', 'fighting'),\n (567, 'voters', 'fbi'),\n (568, 'sources', 'lost'),\n (569, 'energy', 'organization'),\n (570, 'pay', 'term'),\n (571, 'legal', 'inside'),\n (572, 'evidence', 'conference'),\n (573, 'human', 'december'),\n (574, 'running', 'gas'),\n (575, 'attacks', 'hit'),\n (576, 'series', 'involved'),\n (577, 'member', 'economy'),\n (578, 'troops', 'having'),\n (579, 'countries', 'thing'),\n (580, 'victim', 'car'),\n (581, 'saw', 'candidate'),\n (582, 'games', 'killing'),\n (583, 'half', 'son'),\n (584, 'heard', 'questions'),\n (585, 'island', 'saw'),\n (586, 'enforcement', 'happened'),\n (587, 'friends', 'rep'),\n (588, 'bad', 'comments'),\n (589, 'crisis', 'east'),\n (590, 'sent', 'opposition'),\n (591, 'body', 'started'),\n (592, 'issues', 'mother'),\n (593, 'sen', 'building'),\n (594, 'husband', 'reporters'),\n (595, 'possible', 'almost'),\n (596, 'record', 'capitol'),\n (597, 'dead', 'opinion'),\n (598, 'sure', 'ground'),\n (599, 'thought', 'side'),\n (600, 'whose', 'hong'),\n (601, 'provide', 'comment'),\n (602, 'action', 'event'),\n (603, 'florida', 'council'),\n (604, 'gas', 'trial'),\n (605, 'cuomo', 'leave'),\n (606, 'immediately', 'dead'),\n (607, 'page', 'potential'),\n (608, 'victims', 'getting'),\n (609, 'showed', 'message'),\n (610, 'everyone', 'afghanistan'),\n (611, 'tried', 'view'),\n (612, 'inflation', 'job'),\n (613, 'capitol', 'wanted'),\n (614, 'minister', 'instead'),\n (615, 'weapons', 'father'),\n (616, 'actually', 'safety'),\n (617, 'room', 'large'),\n (618, 'incident', 'actions'),\n (619, 'schools', 'street'),\n (620, 'area', 'central'),\n (621, 'conference', 'kong'),\n (622, 'red', 'candidates'),\n (623, 'vice', 'spokesman'),\n (624, 'calling', 'hold'),\n (625, 'race', 'looking'),\n (626, 'future', 'covid'),\n (627, 'presidential', 'calling'),\n (628, 'price', 'reports'),\n (629, 'union', 'feel'),\n (630, 'gave', 'workers'),\n (631, 'role', 'lead'),\n (632, 'meanwhile', 'recently'),\n (633, 'isn', 'sanctions'),\n (634, 'workers', 'middle'),\n (635, 'park', 'running'),\n (636, 'return', 'oil'),\n (637, 'anyone', 'nothing'),\n (638, 'almost', 'claims'),\n (639, 'staff', 'billion'),\n (640, 'cases', 'calls'),\n (641, 'leave', 'laws'),\n (642, 'prison', 'armed'),\n (643, 'event', 'data'),\n (644, 'israel', 'mayor'),\n (645, 'source', 'plans'),\n (646, 'scene', 'capital'),\n (647, 'michael', 'army'),\n (648, 'gop', 'kind'),\n (649, 'often', 'hospital'),\n (650, 'kind', 'became'),\n (651, 'tv', 'executive'),\n (652, 'turned', 'staff'),\n (653, 'further', 'remains'),\n (654, 'met', 'stand'),\n (655, 'tweeted', 'toward'),\n (656, 'became', 'am'),\n (657, 'ex', 'nato'),\n (658, 'moscow', 'hope'),\n (659, 'food', 'small'),\n (660, 'january', 'effort'),\n (661, 'previously', 'crimes'),\n (662, 'private', 'vice'),\n (663, 'release', 'someone'),\n (664, 'course', 'risk'),\n (665, 'received', 'suspect'),\n (666, 'lead', 'ahead'),\n (667, 'data', 'mass'),\n (668, 'medical', 'uk'),\n (669, 'reporters', 'record'),\n (670, 'per', 'supporters'),\n (671, 'online', 'moment'),\n (672, 'tell', 'allies'),\n (673, 'wants', 'murder'),\n (674, 'needs', 'charged'),\n (675, 'sign', 'mexico'),\n (676, 'posted', 'address'),\n (677, 'problem', 'due'),\n (678, 'illegal', 'provide'),\n (679, 'worked', 'western'),\n (680, 'november', 'pay'),\n (681, 'amid', 'body'),\n (682, 'trial', 'democracy'),\n (683, 'book', 'current'),\n (684, 'adding', 'invasion'),\n (685, 'term', 'supreme'),\n (686, 'opens', 'sent'),\n (687, 'documents', 'movement'),\n (688, 'revealed', 'strong'),\n (689, 'question', 'companies'),\n (690, 'families', 'injured'),\n (691, 'happened', 'london'),\n (692, 'crimes', 'note'),\n (693, 'small', 'politics'),\n (694, 'andrew', 'elections'),\n (695, 'click', 'child'),\n (696, 'vladimir', 'expressed'),\n (697, 'talk', 'saudi'),\n (698, 'com', 'access'),\n (699, 'david', 'british'),\n (700, 'harris', 'bring'),\n (701, 'letter', 'concerns'),\n (702, 'paul', 'level'),\n (703, 'seven', 'anything'),\n (704, 'within', 'parents'),\n (705, 'situation', 'remain'),\n (706, 'safe', 'received'),\n (707, 'intelligence', 'medical'),\n (708, 'especially', 'heard'),\n (709, 'played', 'prison'),\n (710, 'thousands', 'half'),\n (711, 'california', 'town'),\n (712, 'potential', 'problem'),\n (713, 'college', 'protect'),\n (714, 'stay', 'violent'),\n (715, 'players', 'thought'),\n (716, 'executive', 'pandemic'),\n (717, 'shared', 'bush'),\n (718, 'ahead', 'means'),\n (719, 'economic', 'pro'),\n (720, 'george', 'forward'),\n (721, 'ny', 'described'),\n (722, 'relationship', 'talk'),\n (723, 'king', 'third'),\n (724, 'suspect', 'assault'),\n (725, 'age', 'agreement'),\n (726, 'large', 'continued'),\n (727, 'prices', 'moscow'),\n (728, 'process', 'especially'),\n (729, 'appeared', 'primary'),\n (730, 'bail', 'terrorist'),\n (731, 'soon', 'sure'),\n (732, 'assault', 'series'),\n (733, 'tax', 'wants'),\n (734, 'prosecutors', 'food'),\n (735, 'policies', 'join'),\n (736, 'try', 'citizens'),\n (737, 'conflict', 'tried'),\n (738, 'points', 'tell'),\n (739, 'oil', 'turkey'),\n (740, 'sanctions', 'hearing'),\n (741, 'afghanistan', 'needs'),\n (742, 'involved', 'fair'),\n (743, 'daily', 'wasn'),\n (744, 'program', 'visit'),\n (745, 'st', 'lawmakers'),\n (746, 'bring', 'letter'),\n (747, 'pro', 'guns'),\n (748, 'fans', 'newsletter'),\n (749, 'hand', 'course'),\n (750, 'fighting', 'decades'),\n (751, 'brother', 'george'),\n (752, 'stand', 'isn'),\n (753, 'majority', 'phone'),\n (754, 'makes', 'whose'),\n (755, 'sex', 'adding'),\n (756, 'career', 'events'),\n (757, 'region', 'french'),\n (758, 'zelensky', 'try'),\n (759, 'wrong', 'fired'),\n (760, 'moment', 'alleged'),\n (761, 'harry', 'energy'),\n (762, 'plans', 'position'),\n (763, 'mexico', 'services'),\n (764, 'threat', 'actually'),\n (765, 'supreme', 'editor'),\n (766, 'final', 'carolina'),\n (767, 'companies', 'tweeted'),\n (768, 'personal', 'scene'),\n (769, 'hold', 'met'),\n (770, 'coronavirus', 'regime'),\n (771, 'prince', 'residents'),\n (772, 'efforts', 'themselves'),\n (773, 'themselves', 'weekend'),\n (774, 'included', 'friends'),\n (775, 'global', 'johnson'),\n (776, 'multiple', 'cannot'),\n (777, 'kyiv', 'wall'),\n (778, 'records', 'ban'),\n (779, 'forward', 'france'),\n (780, 'fired', 'policies'),\n (781, 'reason', 'play'),\n (782, 'hope', 'hate'),\n (783, 'spent', 'safe'),\n (784, 'station', 'cities'),\n (785, 'council', 'return'),\n (786, 'self', 'travel'),\n (787, 'living', 'israeli'),\n (788, 'claim', 'soldiers'),\n (789, 'immigration', 'water'),\n (790, 'violent', 'everyone'),\n (791, 'message', 'un'),\n (792, 'confirmed', 'everything'),\n (793, 'allowed', 'turned'),\n (794, 'ground', 'leadership'),\n (795, 'musk', 'game'),\n (796, 'eric', 'market'),\n (797, 'questions', 'areas'),\n (798, 'pelosi', 'fear'),\n (799, 'clinton', 'makes'),\n (800, 'level', 'final'),\n (801, 'cnn', 'watch'),\n (802, 'wall', 'talks'),\n (803, 'spending', 'voting'),\n (804, 'single', 'soon'),\n (805, 'sports', 'multiple'),\n (806, 'robert', 'personal'),\n (807, 'johnson', 'speaking'),\n (808, 'means', 'david'),\n (809, 'drug', 'words'),\n (810, 'cut', 'love'),\n (811, 'described', 'ministry'),\n (812, 'noted', 'immigrants'),\n (813, 'mom', 'michael'),\n (814, 'check', 'worked'),\n (815, 'current', 'seven'),\n (816, 'eight', 'terrorism'),\n (817, 'october', 'claimed'),\n (818, 'hearing', 'legislation'),\n (819, 'needed', 'anyone'),\n (820, 'august', 'showed'),\n (821, 'economy', 'previously'),\n (822, 'true', 'brought'),\n (823, 'phone', 'result'),\n (824, 'guy', 'leading'),\n (825, 'prime', 'tax'),\n (826, 'knew', 'rally'),\n (827, 'water', 'immediately'),\n (828, 'mass', 'impeachment'),\n (829, 'risk', 'hillary'),\n (830, 'playing', 'appeared'),\n (831, 'mark', 'stay'),\n (832, 'candidate', 'longer'),\n (833, 'lawyer', 'results'),\n (834, 'amazon', 'conservative'),\n (835, 'february', 'refused'),\n (836, 'forced', 'include'),\n (837, 'read', 'similar'),\n (838, 'smith', 'wife'),\n (839, 'watch', 'pressure'),\n (840, 'turn', 'content'),\n (841, 'visit', 'sexual'),\n (842, 'list', 'communities'),\n (843, 'film', 'step'),\n (844, 'short', 'difficult'),\n (845, 'include', 'online'),\n (846, 'felt', 'brown'),\n (847, 'europe', 'room'),\n (848, 'serious', 'aid'),\n (849, 'terms', 'serious'),\n (850, 'brought', 'mark'),\n (851, 'middle', 'prices'),\n (852, 'killing', 'red'),\n (853, 'paid', 'spoke'),\n (854, 'key', 'meet'),\n (855, 'refused', 'governor'),\n (856, 'market', 'college'),\n (857, 'organization', 'republic'),\n (858, 'minutes', 'eastern'),\n (859, 'arrest', 'co'),\n (860, 'remain', 'freedom'),\n (861, 'laws', 'arrest'),\n (862, 'september', 'significant'),\n (863, 'remains', 'allow'),\n (864, 'residents', 'germany'),\n (865, 'groups', 'eight'),\n (866, 'sexual', 'hundreds'),\n (867, 'taliban', 'hands'),\n (868, 'services', 'list'),\n (869, 'failed', 'democrat'),\n (870, 'above', 'student'),\n (871, 'democrat', 'southern'),\n (872, 'girl', 'turn'),\n (873, 'protect', 'attention'),\n (874, 'longer', 'focus'),\n (875, 'either', 'bad'),\n (876, 'leading', 'church'),\n (877, 'hands', 'short'),\n (878, 'al', 'georgia'),\n (879, 'interest', 'either'),\n (880, 'wearing', 'congressional'),\n (881, 'summer', 'amid'),\n (882, 'calls', 'private'),\n (883, 'senior', 'racial'),\n (884, 'los', 'hand'),\n (885, 'site', 'virginia'),\n (886, 'request', 'rather'),\n (887, 'heart', 'board'),\n (888, 'comments', 'king'),\n (889, 'effort', 'reason'),\n (890, 'idea', 'additional'),\n (891, 'rather', 'muslim'),\n (892, 'british', 'poll'),\n (893, 'central', 'living'),\n (894, 'western', 'prosecutors'),\n (895, 'queen', 'research'),\n (896, 'leaving', 'helped'),\n (897, 'space', 'happen'),\n (898, 'additional', 'financial'),\n (899, 'republic', 'increase'),\n (900, 'whole', 'idea'),\n (901, 'allies', 'largest'),\n (902, 'footage', 'critical'),\n (903, 'strong', 'growing'),\n (904, 'denied', 'barack'),\n (905, 'telling', 'talking'),\n (906, 'lawmakers', 'impact'),\n (907, 'meet', 'investigators'),\n (908, 'allow', 'emergency'),\n (909, 'field', 'claim'),\n (910, 'low', 'star'),\n (911, 'coach', 'park'),\n (912, 'lee', 'needed'),\n (913, 'education', 'battle'),\n (914, 'bank', 'chicago'),\n (915, 'blasio', 'failed'),\n (916, 'angeles', 'points'),\n (917, 'hall', 'strike'),\n (918, 'protests', 'documents'),\n (919, 'pair', 'gave'),\n (920, 'financial', 'civilians'),\n (921, 'account', 'understand'),\n (922, 'league', 'de'),\n (923, 'student', 'site'),\n (924, 'although', 'reached'),\n (925, 'available', 'deaths'),\n (926, 'employees', 'forced'),\n (927, 'cities', 'issued'),\n (928, 'warned', 'posted'),\n (929, 'nato', 'bank'),\n (930, 'increase', 'believed'),\n (931, 'words', 'self'),\n (932, 'host', 'experts'),\n (933, 'finally', 'com'),\n (934, 'streets', 'spent'),\n (935, 'toward', 'example'),\n (936, 'southern', 'request'),\n (937, 'town', 'gov'),\n (938, 'protesters', 'raised'),\n (939, 'european', 'refugees'),\n (940, 'spokesman', 'base'),\n (941, 'store', 'allowed'),\n (942, 'photos', 'coronavirus'),\n (943, 'cost', 'passed'),\n (944, 'fellow', 'denied'),\n (945, 'access', 'quickly'),\n (946, 'fair', 'climate'),\n (947, 'december', 'korean'),\n (948, 'experience', 'shootings'),\n (949, 'else', 'daily'),\n (950, 'san', 'victory'),\n (951, 'filed', 'africa'),\n (952, 'uk', 'allegations'),\n (953, 'related', 'age'),\n (954, 'position', 'paul'),\n (955, 'non', 'tv'),\n (956, 'helped', 'included'),\n (957, 'served', 'sources'),\n (958, 'decades', 'interest'),\n (959, 'currently', 'confirmed'),\n (960, 'concerns', 'streets'),\n (961, 'actions', 'relationship'),\n (962, 'talking', 'book'),\n (963, 'couldn', 'felt'),\n (964, 'weekend', 'wrong'),\n (965, 'army', 'daughter'),\n (966, 'mike', 'drug'),\n (967, 'spoke', 'san'),\n (968, 'emergency', 'meanwhile'),\n (969, 'capital', 'india'),\n (970, 'apple', 'speak'),\n (971, 'bronx', 'previous'),\n (972, 'result', 'committed'),\n (973, 'speaker', 'true'),\n (974, 'feb', 'views'),\n (975, 'baby', 'population'),\n (976, 'william', 'particularly'),\n (977, 'trip', 'assad'),\n (979, 'understand', 'domestic'),\n (980, 'total', 'sense'),\n (981, 'citizens', 'votes'),\n (982, 'similar', 'james'),\n (983, 'quickly', 'itself'),\n (984, 'blue', 'warned'),\n (985, 'passed', 'served'),\n (986, 'jones', 'non'),\n (987, 'outlet', 'coalition'),\n (988, 'nations', 'details'),\n (989, 'rules', 'jobs'),\n (990, 'fall', 'cause'),\n (991, 'kremlin', 'biggest'),\n (992, 'door', 'training'),\n (993, 'green', 'although'),\n (994, 'hundreds', 'northern'),\n (995, 'loss', 'schools'),\n (996, 'agents', 'share'),\n (997, 'happen', 'st'),\n (998, 'tiktok', 'ongoing'),\n (999, 'cause', 'measures'),\n (1000, 'signed', 'paris'),\n (1001, 'player', 'experience'),\n (1002, 'maybe', 'threats'),\n (1003, 'guilty', 'numbers'),\n (1004, 'higher', 'low'),\n (1005, 'charge', 'island'),\n (1006, 'williams', 'relations'),\n (1007, 'giving', 'operation'),\n (1008, 'class', 'summer'),\n (1009, 'named', 'mean'),\n (1010, 'style', 'miles'),\n (1011, 'pool', 'single'),\n (1012, 'cannot', 'responded'),\n (1013, 'believed', 'currently'),\n (1014, 'hate', 'follow'),\n (1015, 'born', 'heart'),\n (1016, 'nov', 'identified'),\n ...]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_counts = json.load(open(os.path.join('./models', 'general_word_freq.json'), 'r'))\n",
    "nypost_counts = json.load(open(os.path.join('./models', 'nypost_word_freq.json'), 'r'))\n",
    "cnn_counts = json.load(open(os.path.join('./models', 'cnn_word_freq.json'), 'r'))\n",
    "shared_vocab = set.intersection(set(nypost_counts.keys()), set(cnn_counts.keys()))\n",
    "\n",
    "sorted_w_nypost = sorted(shared_vocab, key=lambda x: nypost_counts[x], reverse=True)\n",
    "sorted_w_cnn = sorted(shared_vocab, key=lambda x: cnn_counts[x], reverse=True)\n",
    "[(i, sorted_w_nypost[i], sorted_w_cnn[i]) for i in range(6000) if sorted_w_cnn[i] != sorted_w_nypost[i]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "311"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shared_vocab = list(sorted(list(set.intersection(set(model_nypost.wv.vocab), set(model_cnn.wv.vocab)))))\n",
    "counts = json.load(open(os.path.join('./models', 'word_freq.json'), 'r'))\n",
    "\n",
    "# get the anchors\n",
    "shared_vocab = set(model_nypost.wv.key_to_index).intersection(set(model_cnn.wv.key_to_index)).intersection(set(model_general.wv.key_to_index))\n",
    "w_counts = [(w, counts[w]) for w in list(shared_vocab)]\n",
    "sorted_w = sorted(shared_vocab, key=lambda x: counts[x], reverse=True)\n",
    "anchors = sorted_w[:1000]\n",
    "\n",
    "stopWords = list(stopWords_s & shared_vocab)\n",
    "len(stopWords)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Aligner(ABC):\n",
    "    def __init__(self, method, source, target, w2id, id2w, mtxA, mtxB, trainvoc):\n",
    "        self.method = method\n",
    "        self.src = source\n",
    "        self.tgt = target\n",
    "        self.w2idA = w2id\n",
    "        self.id2wB = id2w\n",
    "        self.mtxA = mtxA\n",
    "        self.mtxB = mtxB\n",
    "        self.anchors = trainvoc\n",
    "\n",
    "    def translate_mtx(self, mtx):\n",
    "        \"\"\"\n",
    "        MTX -> MTX\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def encode_input(self, words):\n",
    "        \"\"\"\n",
    "        [STRING] -> MTX\n",
    "        \"\"\"\n",
    "        embs = [self.mtxA[self.w2idA[w], :] for w in words]\n",
    "        return np.vstack(embs)\n",
    "\n",
    "    def decode_output(self, mtx, k=1):\n",
    "        \"\"\"\n",
    "        MTX -> [[STRING]]\n",
    "        \"\"\"\n",
    "        similarities = cosine_similarity(mtx, self.mtxB)\n",
    "        most_similar = np.argsort(similarities, axis=1)[:, ::-1]\n",
    "        topsims = np.sort(similarities, axis=1)[:, ::-1][:, :k]\n",
    "        res = [[self.id2wB[i] for i in row[:k]] for row in most_similar]\n",
    "        return res, topsims\n",
    "\n",
    "    def translate_word(self, word, k=1):\n",
    "        \"\"\"\n",
    "        STRING -> STRING\n",
    "        \"\"\"\n",
    "        encoding = self.encode_input([word])\n",
    "        translated = self.translate_mtx(encoding)\n",
    "        decoded = self.decode_output(translated, k=k)\n",
    "        return decoded[0][:k]\n",
    "\n",
    "    def translate_words(self, words, k=1):\n",
    "        \"\"\"\n",
    "        [STRING] -> [STRING]\n",
    "        \"\"\"\n",
    "        encoding = self.encode_input(words)\n",
    "        translated = self.translate_mtx(encoding)\n",
    "        decoded, simscores = self.decode_output(translated, k=k)\n",
    "        return decoded, simscores\n",
    "\n",
    "\n",
    "class CCAAligner(Aligner):\n",
    "    def set_params(self, cca):\n",
    "        self.cca = cca\n",
    "\n",
    "    def translate_mtx(self, mtx):\n",
    "        return mtx\n",
    "\n",
    "    def translate_word(self, word, k=1):\n",
    "        tmpA = self.mtxA\n",
    "        tmpB = self.mtxB\n",
    "        self.mtxA, self.mtxB = self.cca.transform(tmpA, tmpB)\n",
    "        res = super().translate_word(word, k=k)\n",
    "        self.mtxA = tmpA\n",
    "        self.mtxB = tmpB\n",
    "        return res\n",
    "\n",
    "    def translate_words(self, words, k=1):\n",
    "        tmpA = self.mtxA\n",
    "        tmpB = self.mtxB\n",
    "        self.mtxA, self.mtxB = self.cca.transform(tmpA, tmpB)\n",
    "        res, simscores = super().translate_words(words, k=k)\n",
    "        self.mtxA = tmpA\n",
    "        self.mtxB = tmpB\n",
    "        return res, simscores\n",
    "\n",
    "\n",
    "class SVDAligner(Aligner):\n",
    "    def set_params(self, T):\n",
    "        self.T = T\n",
    "\n",
    "    def translate_mtx(self, mtx):\n",
    "        return mtx.dot(self.T)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def align_cca(source, target):\n",
    "    N_dims = source.shape[1]\n",
    "    cca = CCA(n_components=N_dims, max_iter=2000)\n",
    "    cca.fit(source, target)\n",
    "    return cca\n",
    "\n",
    "\n",
    "def align_svd(source, target):\n",
    "    product = np.matmul(source.transpose(), target)\n",
    "    U, s, V = np.linalg.svd(product)\n",
    "    T = np.matmul(U, V)\n",
    "    return T\n",
    "\n",
    "\n",
    "def get_cca_aligner(model_a, model_b, anchorlist):\n",
    "    # get wordmaps\n",
    "    awords = list(sorted(list(model_a.wv.key_to_index)))\n",
    "    bwords = list(sorted(list(model_b.wv.key_to_index)))\n",
    "    w2idA = {w: i for i, w in enumerate(awords)}\n",
    "    id2wA = {i: w for i, w in enumerate(awords)}\n",
    "    w2idB = {w: i for i, w in enumerate(bwords)}\n",
    "    id2wB = {i: w for i, w in enumerate(bwords)}\n",
    "\n",
    "    # build the base matrices\n",
    "    a_mtx = np.vstack([model_a.wv[w] for w in awords])\n",
    "    b_mtx = np.vstack([model_b.wv[w] for w in bwords])\n",
    "\n",
    "    # get the anchors\n",
    "    a_anchor = np.vstack([a_mtx[w2idA[w], :] for w in anchorlist])\n",
    "    b_anchor = np.vstack([b_mtx[w2idB[w], :] for w in anchorlist])\n",
    "\n",
    "    # compute CCA\n",
    "    cca = align_cca(a_anchor, b_anchor)\n",
    "\n",
    "    # build and return the aligner\n",
    "    aligner = CCAAligner('cca', model_a, model_b, w2idA, id2wB, a_mtx, b_mtx, anchorlist)\n",
    "    aligner.set_params(cca)\n",
    "    return aligner\n",
    "\n",
    "\n",
    "def get_svd_aligner(model_a, model_b, anchorlist):\n",
    "    # get wordmaps\n",
    "    awords = list(sorted(list(model_a.wv.vocab)))\n",
    "    bwords = list(sorted(list(model_b.wv.vocab)))\n",
    "    w2idA = {w: i for i, w in enumerate(awords)}\n",
    "    w2idB = {w: i for i, w in enumerate(bwords)}\n",
    "    id2wB = {i: w for i, w in enumerate(bwords)}\n",
    "\n",
    "    # build the base matrices\n",
    "    a_mtx = np.vstack([model_a.wv[w] for w in awords])\n",
    "    b_mtx = np.vstack([model_b.wv[w] for w in bwords])\n",
    "    print(a_mtx.shape, b_mtx.shape)\n",
    "\n",
    "    # get the anchors\n",
    "    a_anchor = np.vstack([a_mtx[w2idA[w], :] for w in anchorlist])\n",
    "    b_anchor = np.vstack([b_mtx[w2idB[w], :] for w in anchorlist])\n",
    "\n",
    "    # get the translation matrix\n",
    "    T = align_svd(a_anchor, b_anchor)\n",
    "\n",
    "    # build and return the aligner\n",
    "    aligner = SVDAligner('svd', model_a, model_b, w2idA, id2wB, a_mtx, b_mtx, anchorlist)\n",
    "    aligner.set_params(T)\n",
    "    return aligner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "aligner_cnn = get_cca_aligner(model_cnn, model_general, stopWords)\n",
    "pickle.dump(aligner_cnn, open(os.path.join('./models', 'align_cnn.pkl'), 'wb'))\n",
    "aligner_nypost = get_cca_aligner(model_nypost, model_general, stopWords)\n",
    "pickle.dump(aligner_nypost, open(os.path.join('./models', 'align_nypost.pkl'), 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['prosecutor', 'younger', 'hugely', 'mysterious', 'spin', 'realizing', 'toe', 'berlin', 'bowl', 'dealings']] [['aligned', 'president', 'oprah', 'relentless', 'cefc', 'mayors', 'disclosure', 'traveling', 'david', 'iran']]\n"
     ]
    }
   ],
   "source": [
    "forward_cnn = pickle.load(open(os.path.join('./models', 'align_cnn.pkl'), 'rb'))\n",
    "forward_nypost = pickle.load(open(os.path.join('./models', 'align_nypost.pkl'), 'rb'))\n",
    "check = 'obama'\n",
    "print(forward_cnn.translate_word(check, k=10), forward_nypost.translate_word(check, k=10))\n",
    "ny_map=forward_nypost.translate_mtx(model_nypost.wv[check])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "        general           cnn         nypost\n0        uphold  institutions  psychological\n1     buildings    militarily        fueling\n2  accidentally           won      afternoon\n3     christina         comey      arresting\n4       cameron       curious        payment\n5          test   willingness         prices\n6         labor       rioting          argue\n7       brennan         grown      pakistani\n8     thousands   restrictive           vest\n9          grab     determine       function",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>uphold</td>\n      <td>institutions</td>\n      <td>psychological</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>buildings</td>\n      <td>militarily</td>\n      <td>fueling</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>accidentally</td>\n      <td>won</td>\n      <td>afternoon</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>christina</td>\n      <td>comey</td>\n      <td>arresting</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cameron</td>\n      <td>curious</td>\n      <td>payment</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>test</td>\n      <td>willingness</td>\n      <td>prices</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>labor</td>\n      <td>rioting</td>\n      <td>argue</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>brennan</td>\n      <td>grown</td>\n      <td>pakistani</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>thousands</td>\n      <td>restrictive</td>\n      <td>vest</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>grab</td>\n      <td>determine</td>\n      <td>function</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='Trump'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      general            cnn     nypost\n0     masking     federation      kenya\n1     section        heinous     arpaio\n2     absence      computers   mccarthy\n3       clerk          ended   required\n4     angeles       systemic     knicks\n5   offenders       employed    authors\n6      limits         rocket      email\n7      invite       exercise  lawmakers\n8  collection  manufacturing     harden\n9       olive          sides       chip",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>masking</td>\n      <td>federation</td>\n      <td>kenya</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>section</td>\n      <td>heinous</td>\n      <td>arpaio</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>absence</td>\n      <td>computers</td>\n      <td>mccarthy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>clerk</td>\n      <td>ended</td>\n      <td>required</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>angeles</td>\n      <td>systemic</td>\n      <td>knicks</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>offenders</td>\n      <td>employed</td>\n      <td>authors</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>limits</td>\n      <td>rocket</td>\n      <td>email</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>invite</td>\n      <td>exercise</td>\n      <td>lawmakers</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>collection</td>\n      <td>manufacturing</td>\n      <td>harden</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>olive</td>\n      <td>sides</td>\n      <td>chip</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='democratic'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "        general           cnn        nypost\n0     paramount      provoked         balls\n1       culture          duke      mulvaney\n2        causes        states         shock\n3    organizing         megan         james\n4       answers  deliberately    interested\n5  championship        fields    expression\n6     colleague         stark    supporting\n7       fantasy     reopening  subcommittee\n8          euro       emailed  pennsylvania\n9       lincoln         suing  presentation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>paramount</td>\n      <td>provoked</td>\n      <td>balls</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>culture</td>\n      <td>duke</td>\n      <td>mulvaney</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>causes</td>\n      <td>states</td>\n      <td>shock</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>organizing</td>\n      <td>megan</td>\n      <td>james</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>answers</td>\n      <td>deliberately</td>\n      <td>interested</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>championship</td>\n      <td>fields</td>\n      <td>expression</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>colleague</td>\n      <td>stark</td>\n      <td>supporting</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>fantasy</td>\n      <td>reopening</td>\n      <td>subcommittee</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>euro</td>\n      <td>emailed</td>\n      <td>pennsylvania</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>lincoln</td>\n      <td>suing</td>\n      <td>presentation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='war'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "        general       cnn     nypost\n0        kimmel  properly     taiwan\n1           saw      tass      votes\n2          bent  applause     vacuum\n3     mcauliffe      ours     thirty\n4     nominated     foley   carriers\n5        alexis   scoring    cruelty\n6  coordination      hook    largely\n7      rallying   offices     dayton\n8  corporations  zelensky    goldman\n9  shutterstock      seed  happiness",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kimmel</td>\n      <td>properly</td>\n      <td>taiwan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>saw</td>\n      <td>tass</td>\n      <td>votes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bent</td>\n      <td>applause</td>\n      <td>vacuum</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mcauliffe</td>\n      <td>ours</td>\n      <td>thirty</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>nominated</td>\n      <td>foley</td>\n      <td>carriers</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>alexis</td>\n      <td>scoring</td>\n      <td>cruelty</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>coordination</td>\n      <td>hook</td>\n      <td>largely</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>rallying</td>\n      <td>offices</td>\n      <td>dayton</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>corporations</td>\n      <td>zelensky</td>\n      <td>goldman</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>shutterstock</td>\n      <td>seed</td>\n      <td>happiness</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='terror'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       general            cnn        nypost\n0    sentences         afghan       genuine\n1        louis          dodge    petersburg\n2         line           omar     protester\n3    lucrative  unfortunately          bail\n4      gabriel            cdc         tower\n5  shoplifting     democratic        bergen\n6      apology         collar  disappointed\n7           me          boris          lady\n8    nightmare        shouted    compassion\n9          aew         oxygen    foreigners",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sentences</td>\n      <td>afghan</td>\n      <td>genuine</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>louis</td>\n      <td>dodge</td>\n      <td>petersburg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>line</td>\n      <td>omar</td>\n      <td>protester</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lucrative</td>\n      <td>unfortunately</td>\n      <td>bail</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gabriel</td>\n      <td>cdc</td>\n      <td>tower</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>shoplifting</td>\n      <td>democratic</td>\n      <td>bergen</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>apology</td>\n      <td>collar</td>\n      <td>disappointed</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>me</td>\n      <td>boris</td>\n      <td>lady</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>nightmare</td>\n      <td>shouted</td>\n      <td>compassion</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>aew</td>\n      <td>oxygen</td>\n      <td>foreigners</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='ukraine'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "      general           cnn      nypost\n0    richmond       seizing  everything\n1        more          keys   moderates\n2        rare         deals       brush\n3      elites      storming   describes\n4         arm       boarded       grand\n5     overall      resulted       dutch\n6      ashley      approach       jerry\n7     sisters       pacific       issue\n8  staggering         punch     prevail\n9     hacking  marginalized    equality",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>richmond</td>\n      <td>seizing</td>\n      <td>everything</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>more</td>\n      <td>keys</td>\n      <td>moderates</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>rare</td>\n      <td>deals</td>\n      <td>brush</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>elites</td>\n      <td>storming</td>\n      <td>describes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arm</td>\n      <td>boarded</td>\n      <td>grand</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>overall</td>\n      <td>resulted</td>\n      <td>dutch</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ashley</td>\n      <td>approach</td>\n      <td>jerry</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>sisters</td>\n      <td>pacific</td>\n      <td>issue</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>staggering</td>\n      <td>punch</td>\n      <td>prevail</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>hacking</td>\n      <td>marginalized</td>\n      <td>equality</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='violence'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      general             cnn     nypost\n0     acquire         tonight    remarks\n1      berman      provisions  newspaper\n2     vermont      passionate       name\n3  abramovich          expect   extended\n4      actors           stood      false\n5      career          victim  paralyzed\n6      expire  investigations        gig\n7       dirty         runners  dedicated\n8   suffering      vulnerable   peterson\n9     divorce         robbery  processed",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>acquire</td>\n      <td>tonight</td>\n      <td>remarks</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>berman</td>\n      <td>provisions</td>\n      <td>newspaper</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vermont</td>\n      <td>passionate</td>\n      <td>name</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abramovich</td>\n      <td>expect</td>\n      <td>extended</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>actors</td>\n      <td>stood</td>\n      <td>false</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>career</td>\n      <td>victim</td>\n      <td>paralyzed</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>expire</td>\n      <td>investigations</td>\n      <td>gig</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>dirty</td>\n      <td>runners</td>\n      <td>dedicated</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>suffering</td>\n      <td>vulnerable</td>\n      <td>peterson</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>divorce</td>\n      <td>robbery</td>\n      <td>processed</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='gun'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "        general           cnn         nypost\n0        uphold  institutions  psychological\n1     buildings    militarily        fueling\n2  accidentally           won      afternoon\n3     christina         comey      arresting\n4       cameron       curious        payment\n5          test   willingness         prices\n6         labor       rioting          argue\n7       brennan         grown      pakistani\n8     thousands   restrictive           vest\n9          grab     determine       function",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>uphold</td>\n      <td>institutions</td>\n      <td>psychological</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>buildings</td>\n      <td>militarily</td>\n      <td>fueling</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>accidentally</td>\n      <td>won</td>\n      <td>afternoon</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>christina</td>\n      <td>comey</td>\n      <td>arresting</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cameron</td>\n      <td>curious</td>\n      <td>payment</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>test</td>\n      <td>willingness</td>\n      <td>prices</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>labor</td>\n      <td>rioting</td>\n      <td>argue</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>brennan</td>\n      <td>grown</td>\n      <td>pakistani</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>thousands</td>\n      <td>restrictive</td>\n      <td>vest</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>grab</td>\n      <td>determine</td>\n      <td>function</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='trump'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "        general         cnn        nypost\n0  capabilities   framework  intimidation\n1       utility        boko       seventh\n2    withdrawal        text   congressman\n3        eagles         nra        chosen\n4          east         sub         ideal\n5         slash    alliance        invest\n6         group  categories    population\n7        talent       chips     permanent\n8       coastal   declaring           god\n9       studies  speculated        bulger",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>general</th>\n      <th>cnn</th>\n      <th>nypost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>capabilities</td>\n      <td>framework</td>\n      <td>intimidation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>utility</td>\n      <td>boko</td>\n      <td>seventh</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>withdrawal</td>\n      <td>text</td>\n      <td>congressman</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eagles</td>\n      <td>nra</td>\n      <td>chosen</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>east</td>\n      <td>sub</td>\n      <td>ideal</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>slash</td>\n      <td>alliance</td>\n      <td>invest</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>group</td>\n      <td>categories</td>\n      <td>population</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>talent</td>\n      <td>chips</td>\n      <td>permanent</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>coastal</td>\n      <td>declaring</td>\n      <td>god</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>studies</td>\n      <td>speculated</td>\n      <td>bulger</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check='republic'.lower()\n",
    "pd.DataFrame({\n",
    "    'general':[x[0] for x in model_general.wv.most_similar(check,topn=10)],\n",
    "    'cnn':forward_cnn.translate_word(check, k=10)[0],\n",
    "    'nypost':forward_nypost.translate_word(check, k=10)[0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.10958398]], dtype=float32)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_map=forward_cnn.translate_mtx(model_cnn.wv[check])\n",
    "cosine_similarity(np.array(ny_map).reshape([1,-1]),np.array(cn_map).reshape([1,-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-4.8772991e-04,  1.1522899e-03,  2.4335664e-03, -4.7192629e-03,\n       -6.4384425e-04,  1.1733546e-03, -1.5236151e-04, -7.1559887e-04,\n       -4.3369326e-04, -7.0619880e-04,  3.0788688e-03, -2.7435201e-03,\n       -3.1751040e-03,  1.6124884e-03,  2.7763851e-03,  3.6839894e-05,\n        1.2720450e-03, -3.2315950e-03, -1.7085986e-03,  2.5071877e-03,\n        2.8880301e-03,  7.6024956e-04,  4.0266859e-05, -2.4150165e-03,\n       -3.1555486e-03,  1.2078570e-03,  1.0000559e-03, -9.0697251e-04,\n        3.9538718e-03, -2.3819534e-03, -2.1351140e-03,  1.0470392e-03,\n       -3.8495401e-03, -3.8961619e-03, -2.8486853e-03,  3.3731149e-03,\n       -3.0843297e-03,  3.1627556e-03,  3.1393261e-03,  4.3007167e-04,\n       -2.5811319e-03, -2.4852389e-04,  4.3256641e-03,  2.3485398e-05,\n       -2.7441173e-03,  1.2207074e-03,  1.5250307e-03, -2.7754339e-03,\n       -1.4661993e-03, -3.1597859e-03,  4.6035620e-05,  1.9733724e-03,\n        9.4898103e-04,  4.0502232e-03, -3.6525528e-03, -4.1148660e-04,\n       -3.2392910e-03, -3.7627015e-03, -2.8581999e-03,  1.1470289e-03,\n       -2.7163094e-03,  2.0048530e-03, -4.5970972e-03, -2.4515535e-03,\n       -2.9152774e-03, -2.2588642e-03,  2.5792673e-04,  4.4196453e-03,\n       -1.1892704e-03,  3.1156060e-03, -2.1339864e-03, -3.4322427e-03,\n        1.6883463e-03,  1.4146973e-05, -3.5295137e-03,  4.2915698e-03,\n        1.1894340e-03,  4.2552226e-03,  4.5847693e-03, -2.3431606e-03,\n       -2.9916032e-03,  8.4125792e-04, -2.1483731e-03,  3.0683903e-03,\n        4.0367860e-03, -2.0707634e-03, -4.3807076e-03, -3.8796747e-03,\n       -3.1553253e-03, -1.6277531e-03,  2.4341415e-03,  9.5059705e-04,\n        5.5901124e-04, -4.4237049e-03,  4.1595715e-04, -1.0812789e-03,\n       -1.6272482e-03, -3.2640304e-03, -4.3086945e-03, -3.3832376e-03],\n      dtype=float32)"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_general.wv[check]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "['the',\n 'to',\n 'of',\n 'and',\n 'in',\n 'that',\n 'on',\n 'for',\n 'is',\n 'said',\n 'it',\n 'he',\n 'was',\n 'with',\n 'as',\n 'at',\n 'his',\n 'have',\n 'are',\n 'has',\n 'from',\n 'by',\n 'be',\n 'not',\n 'this',\n 'an',\n 'but',\n 'they',\n 'we',\n 'trump',\n 'who',\n 'cnn',\n 'will',\n 'were',\n 'their',\n 'been',\n 'people',\n 'about',\n 'us',\n 'more',\n 'president',\n 'she',\n 'or',\n 'had',\n 'after',\n 'one',\n 'you',\n 'her',\n 'police',\n 'would',\n 'there',\n 'new',\n 'what',\n 'also',\n 'when',\n 'which',\n 'up',\n 'out',\n 'its',\n 'all',\n 'if',\n 'year',\n 'our',\n 'than',\n 'can',\n 'no',\n 'two',\n 'told',\n 'other',\n 'over',\n 'some',\n 'state',\n 'time',\n 'so',\n 'into',\n 'first',\n 'according',\n 'could',\n 'last',\n 'country',\n 'him',\n 'them',\n 'house',\n 'against',\n 'just',\n 'war',\n 'like',\n 'government',\n 'during',\n 'now',\n 'do',\n 'years',\n 'those',\n 'how',\n 'many',\n 'says',\n 'while',\n 'russia',\n 'states',\n 'because',\n 'before',\n 'world',\n 'white',\n 'where',\n 'most',\n 'day',\n 'united',\n 'any',\n 'ukraine',\n 'get',\n 'may',\n 'only',\n 'even',\n 're',\n 'being',\n 'my',\n 'say',\n 'black',\n 'did',\n 'city',\n 'images',\n 'military',\n 'security',\n 'back',\n 'video',\n 'week',\n 'since',\n 'russian',\n 'national',\n 'law',\n 'former',\n 'these',\n 'made',\n 'attack',\n 'biden',\n 'american',\n 'including',\n 'statement',\n 'getty',\n 'then',\n 'story',\n 'officials',\n 'between',\n 'group',\n 'court',\n 'still',\n 'going',\n 'political',\n 'democratic',\n 'don',\n 'make',\n 'department',\n 'should',\n 'violence',\n 'public',\n 'three',\n 'very',\n 'know',\n 'down',\n 'take',\n 'campaign',\n 'here',\n 'through',\n 'way',\n 'called',\n 'news',\n 'family',\n 'support',\n 'killed',\n 'right',\n 'election',\n 'think',\n 'your',\n 'tuesday',\n 'both',\n 'another',\n 'republican',\n 'administration',\n 'gun',\n 'obama',\n 'under',\n 'part',\n 'well',\n 'party',\n 'women',\n 'long',\n 'china',\n 'office',\n 'much',\n 'around',\n 'monday',\n 'man',\n 'wednesday',\n 'home',\n 'such',\n 'me',\n 'old',\n 'off',\n 'want',\n 'see',\n 'washington',\n 'work',\n 'thursday',\n 'need',\n 'friday',\n 'democrats',\n 'case',\n 'officers',\n 'rights',\n 'go',\n 'donald',\n 'ad',\n 'days',\n 'members',\n 'own',\n 'york',\n 'children',\n 'media',\n 'federal',\n 'clinton',\n 'report',\n 'same',\n 'school',\n 'million',\n 'forces',\n 'north',\n 'source',\n 'south',\n 'international',\n 'senate',\n 'help',\n 'found',\n 'month',\n 'life',\n 'america',\n 'syria',\n 'next',\n 'al',\n 'official',\n 'high',\n 'end',\n 'come',\n 'later',\n 'whether',\n 'death',\n 'never',\n 'saying',\n 'left',\n 'isis',\n 'justice',\n 'asked',\n 'used',\n 'shooting',\n 'highlights',\n 'use',\n 'today',\n 'americans',\n 'among',\n 'health',\n 'place',\n 'foreign',\n 'several',\n 'republicans',\n 'recent',\n 'attacks',\n 'border',\n 'policy',\n 'community',\n 'least',\n 'why',\n 'across',\n 'investigation',\n 'took',\n 'sunday',\n 'officer',\n 'four',\n 've',\n 'putin',\n 'too',\n 'added',\n 'didn',\n 'vote',\n 'months',\n 'number',\n 'every',\n 'show',\n 'countries',\n 'far',\n 'defense',\n 'authorities',\n 'without',\n 'reported',\n 'times',\n 'committee',\n 'power',\n 'attorney',\n 'general',\n 'leaders',\n 'night',\n 'immigration',\n 'bill',\n 'came',\n 'things',\n 'call',\n 'men',\n 'minister',\n 'seen',\n 'congress',\n 'twitter',\n 'second',\n 'presidential',\n 'afp',\n 'leader',\n 'history',\n 'past',\n 'good',\n 'decision',\n 'secretary',\n 'earlier',\n 'change',\n 'top',\n 'others',\n 'force',\n 'already',\n 'march',\n 'put',\n 'january',\n 'university',\n 'clear',\n 'shot',\n 'iran',\n 'crime',\n 'chief',\n 'center',\n 'deal',\n 'protesters',\n 'saturday',\n 'nation',\n 'away',\n 'does',\n 'team',\n 'wrote',\n 'voters',\n 'won',\n 'though',\n 'social',\n 'likely',\n 'local',\n 'again',\n 'set',\n 'point',\n 'five',\n 'groups',\n 'feedback',\n 'really',\n 'something',\n 'issue',\n 'person',\n 'information',\n 'control',\n 'working',\n 'yet',\n 'early',\n 'issues',\n 'until',\n 'face',\n 'anti',\n 'must',\n 'released',\n 'believe',\n 'ukrainian',\n 'few',\n 'outside',\n 'might',\n 'taken',\n 'human',\n 'conflict',\n 'major',\n 'near',\n 'company',\n 'fire',\n 'led',\n 'sen',\n 'woman',\n 'weapons',\n 'doesn',\n 'held',\n 'making',\n 'following',\n 'enforcement',\n 'november',\n 'trying',\n 'look',\n 'meeting',\n 'race',\n 'related',\n 'lot',\n 'action',\n 'business',\n 'lives',\n 'announced',\n 'move',\n 'stop',\n 'known',\n 'weeks',\n 'based',\n 'continue',\n 'read',\n 'system',\n 'john',\n 'got',\n 'order',\n 'each',\n 'director',\n 'act',\n 'civil',\n 'become',\n 'iraq',\n 'run',\n 'gop',\n 'response',\n 'ap',\n 'free',\n 'protests',\n 'syrian',\n 'young',\n 'fight',\n 'however',\n 'june',\n 'facebook',\n 'little',\n 'went',\n 'county',\n 'died',\n 'big',\n 'district',\n 'area',\n 'agency',\n 'different',\n 'best',\n 'post',\n 'care',\n 'air',\n 'important',\n 'comes',\n 'korea',\n 'great',\n 'evidence',\n 'ago',\n 'region',\n 'able',\n 'legal',\n 'intelligence',\n 'september',\n 'troops',\n 'began',\n 'economic',\n 'morning',\n 'service',\n 'victims',\n 'press',\n 'plan',\n 'west',\n 'start',\n 'process',\n 'taking',\n 'once',\n 'less',\n 'behind',\n 'sign',\n 'better',\n 'july',\n 'open',\n 'doing',\n 'chinese',\n 'europe',\n 'crisis',\n 'nearly',\n 'keep',\n 'european',\n 'protest',\n 'sanders',\n 'fact',\n 'efforts',\n 'speech',\n 'california',\n 'prime',\n 'union',\n 'money',\n 'cases',\n 'matter',\n 'students',\n 'six',\n 'threat',\n 'trade',\n 'despite',\n 'global',\n 'interview',\n 'debate',\n 'february',\n 'let',\n 'families',\n 'nuclear',\n 'incident',\n 'given',\n 'texas',\n 'senior',\n 'possible',\n 'october',\n 'arrested',\n 'head',\n 'hours',\n 'august',\n 'find',\n 'future',\n 'close',\n 'give',\n 'criminal',\n 'ever',\n 'along',\n 'charges',\n 'often',\n 'real',\n 'israel',\n 'situation',\n 'together',\n 'full',\n 'role',\n 'done',\n 'within',\n 'himself',\n 'special',\n 'further',\n 'majority',\n 'late',\n 'line',\n 'peace',\n 'win',\n 'april',\n 'nations',\n 'question',\n 'joe',\n 'key',\n 'program',\n 'name',\n 'enough',\n 'member',\n 'using',\n 'live',\n 'release',\n 'expected',\n 'front',\n 'll',\n 'th',\n 'florida',\n 'always',\n 'terror',\n 'coming',\n 'shows',\n 'african',\n 'accused',\n 'thousands',\n 'hard',\n 'judge',\n 'latest',\n 'fighting',\n 'fbi',\n 'lost',\n 'organization',\n 'term',\n 'inside',\n 'conference',\n 'december',\n 'gas',\n 'hit',\n 'involved',\n 'economy',\n 'having',\n 'thing',\n 'car',\n 'candidate',\n 'killing',\n 'son',\n 'questions',\n 'saw',\n 'happened',\n 'rep',\n 'comments',\n 'east',\n 'opposition',\n 'started',\n 'mother',\n 'building',\n 'reporters',\n 'almost',\n 'capitol',\n 'opinion',\n 'ground',\n 'side',\n 'hong',\n 'comment',\n 'event',\n 'council',\n 'trial',\n 'leave',\n 'dead',\n 'potential',\n 'getting',\n 'message',\n 'afghanistan',\n 'view',\n 'job',\n 'wanted',\n 'instead',\n 'father',\n 'safety',\n 'large',\n 'actions',\n 'street',\n 'central',\n 'kong',\n 'candidates',\n 'spokesman',\n 'hold',\n 'looking',\n 'covid',\n 'calling',\n 'reports',\n 'feel',\n 'workers',\n 'lead',\n 'recently',\n 'sanctions',\n 'middle',\n 'running',\n 'oil',\n 'nothing',\n 'claims',\n 'billion',\n 'calls',\n 'laws',\n 'armed',\n 'data',\n 'mayor',\n 'plans',\n 'capital',\n 'army',\n 'kind',\n 'hospital',\n 'became',\n 'executive',\n 'staff',\n 'remains',\n 'stand',\n 'toward',\n 'am',\n 'nato',\n 'hope',\n 'small',\n 'effort',\n 'crimes',\n 'vice',\n 'someone',\n 'risk',\n 'suspect',\n 'ahead',\n 'mass',\n 'uk',\n 'record',\n 'supporters',\n 'moment',\n 'allies',\n 'murder',\n 'charged',\n 'mexico',\n 'address',\n 'due',\n 'provide',\n 'western',\n 'pay',\n 'body',\n 'democracy',\n 'current',\n 'invasion',\n 'supreme',\n 'sent',\n 'movement',\n 'strong',\n 'companies',\n 'injured',\n 'london',\n 'note',\n 'politics',\n 'elections',\n 'child',\n 'expressed',\n 'saudi',\n 'access',\n 'british',\n 'bring',\n 'concerns',\n 'level',\n 'anything',\n 'parents',\n 'remain',\n 'received',\n 'medical',\n 'heard',\n 'prison',\n 'half',\n 'town',\n 'problem',\n 'protect',\n 'violent',\n 'thought',\n 'pandemic',\n 'bush',\n 'means',\n 'pro',\n 'forward',\n 'described',\n 'talk',\n 'third',\n 'assault',\n 'agreement',\n 'continued',\n 'moscow',\n 'especially',\n 'primary',\n 'terrorist',\n 'sure',\n 'series',\n 'wants',\n 'food',\n 'join',\n 'citizens',\n 'tried',\n 'tell',\n 'turkey',\n 'hearing',\n 'needs',\n 'fair',\n 'wasn',\n 'visit',\n 'lawmakers',\n 'letter',\n 'guns',\n 'newsletter',\n 'course',\n 'decades',\n 'george',\n 'isn',\n 'phone',\n 'whose',\n 'adding',\n 'events',\n 'french',\n 'try',\n 'fired',\n 'alleged',\n 'energy',\n 'position',\n 'services',\n 'actually',\n 'editor',\n 'carolina',\n 'tweeted',\n 'met',\n 'scene',\n 'regime',\n 'residents',\n 'themselves',\n 'weekend',\n 'friends',\n 'johnson',\n 'cannot',\n 'wall',\n 'ban',\n 'france',\n 'policies',\n 'play',\n 'hate',\n 'safe',\n 'cities',\n 'return',\n 'travel',\n 'israeli',\n 'soldiers',\n 'water',\n 'un',\n 'everyone',\n 'everything',\n 'turned',\n 'leadership',\n 'market',\n 'game',\n 'areas',\n 'fear',\n 'makes',\n 'final',\n 'talks',\n 'watch',\n 'voting',\n 'soon',\n 'multiple',\n 'personal',\n 'speaking',\n 'david',\n 'words',\n 'love',\n 'ministry',\n 'immigrants',\n 'michael',\n 'worked',\n 'seven',\n 'terrorism',\n 'legislation',\n 'claimed',\n 'anyone',\n 'showed',\n 'previously',\n 'brought',\n 'result',\n 'leading',\n 'tax',\n 'rally',\n 'immediately',\n 'impeachment',\n 'hillary',\n 'appeared',\n 'stay',\n 'longer',\n 'results',\n 'conservative',\n 'refused',\n 'include',\n 'similar',\n 'wife',\n 'pressure',\n 'content',\n 'sexual',\n 'communities',\n 'step',\n 'difficult',\n 'online',\n 'brown',\n 'room',\n 'aid',\n 'serious',\n 'mark',\n 'prices',\n 'red',\n 'spoke',\n 'meet',\n 'governor',\n 'college',\n 'republic',\n 'eastern',\n 'co',\n 'freedom',\n 'arrest',\n 'significant',\n 'allow',\n 'germany',\n 'eight',\n 'hundreds',\n 'hands',\n 'list',\n 'democrat',\n 'student',\n 'southern',\n 'turn',\n 'attention',\n 'focus',\n 'bad',\n 'church',\n 'short',\n 'georgia',\n 'either',\n 'congressional',\n 'amid',\n 'private',\n 'racial',\n 'hand',\n 'virginia',\n 'rather',\n 'board',\n 'king',\n 'reason',\n 'additional',\n 'muslim',\n 'poll',\n 'living',\n 'prosecutors',\n 'research',\n 'helped',\n 'happen',\n 'financial',\n 'increase',\n 'idea',\n 'largest',\n 'critical',\n 'growing',\n 'barack',\n 'talking',\n 'impact',\n 'investigators',\n 'emergency',\n 'claim',\n 'star',\n 'park',\n 'needed',\n 'battle',\n 'chicago',\n 'failed',\n 'points',\n 'strike',\n 'documents',\n 'gave',\n 'civilians',\n 'understand',\n 'de',\n 'site',\n 'reached',\n 'deaths',\n 'forced',\n 'issued',\n 'posted',\n 'bank',\n 'believed',\n 'self',\n 'experts',\n 'com',\n 'spent',\n 'example',\n 'request',\n 'gov',\n 'raised',\n 'refugees',\n 'base',\n 'allowed',\n 'coronavirus',\n 'passed',\n 'denied',\n 'quickly',\n 'climate',\n 'korean',\n 'shootings',\n 'daily',\n 'victory',\n 'africa',\n 'allegations',\n 'age',\n 'paul',\n 'tv',\n 'included',\n 'sources',\n 'interest',\n 'confirmed',\n 'streets',\n 'relationship',\n 'book',\n 'felt',\n 'wrong',\n 'daughter',\n 'drug',\n 'san',\n 'meanwhile',\n 'india',\n 'speak',\n 'previous',\n 'committed',\n 'true',\n 'views',\n 'population',\n 'particularly',\n 'assad',\n 'dangerous',\n 'domestic',\n 'sense',\n 'votes',\n 'james',\n 'itself',\n 'warned',\n 'served',\n 'non',\n 'coalition',\n 'details',\n 'jobs',\n 'cause',\n 'biggest',\n 'training',\n 'although',\n 'northern',\n 'schools',\n 'share',\n 'st',\n 'ongoing',\n 'measures',\n 'paris',\n ...]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_cnn.wv.index_to_key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnn_counts = json.load(open(os.path.join('./models', 'cnn_word_freq.json'), 'r'))\n",
    "sorted_w = sorted(shared_vocab, key=lambda x: cnn_counts[x], reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model_nypost.wv.save(os.path.join('./models','nypost.wv'))\n",
    "model_cnn.wv.save(os.path.join('./models','cnn.model'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
